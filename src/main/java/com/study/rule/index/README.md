


指标模型对象包含事件(模型)ID、指标名称、计算方式、搜索字段(主维度)、统计字段(从维度)、时间间隔(时间片)等字段。其中主维度至少有一个，从维度最多有一个；
计算指标的方式包括求总数、求和、求平均值、求最大值、求最小值等方式。

指标计算：一般包括高频类统计、求和、计数、求平均值、求最大值、求最小值等等；


### 1、考拉海购指标key的设计


若有这样一个指标：“最近10分钟，同一个账号在同一个商家的下单金额”，那么主维度就是下单账号+商家id，从维度就是订单金额。
可以看到，这里的主维度相当于sql里面的group by，从维度相当于count，数值累加相当于sum。从关于指标计算，有几点说明下：

#### key的构成
考拉海购的指标存储是用的redis，这里会涉及到一个key该如何设计的问题。他们的做法是：
> key = [指标id] + [版本号] + [主维度值] + [时间间隔序号]


1)、指标id就是指标模型对象的唯一标示；
2)、版本号是**指标对象的版本**，每次更新完指标都会更新对应的版本号，这样可以让就的指标一次全部失效；
指标模型对象包含version字段，每次更新指标都会更新对应的版本号;
Q1:指标对象更新后，redis中的指标数据就全部失效了要重新开始计算
Q2:redis key存储的有效生命周期？是否需要持久化？

3)、主维度值是指当前事件对象中，主维度字段对应的值，比如一个下单事件，主维度是用户账号，那么这里就是对应的类似XXX@163.com，如果有多个主维度则需要全部组装上去；

+ 如果主维度的值出现中文，这样直接拼接在key里面会有问题，可以采用转义或者md5的方式进行。

4)、时间间隔序号是指当前时间减去指标最后更新时间，得到的差值再除以采样周期，得到一个序号。这么做主要是为了实现指标的滑动窗口计算，下面会讲


### 滑动窗口计算？
比如我们的指标是最近10分钟的同一用户的下单量，那么我们就需要实现一种类似的滑动窗口算法，以便任何时候都能拿到“最近10分钟”的数据。
这里我们采用的是一种简单的算法：创建指标时，指定好采样次数。比如要获取“最近10分钟”的数据，采样次数设置成30次，这样我们会把每隔20秒的数据会放入一个key里面。
每次一个下单事件过来时，计算出时间间隔序号（见第1点），然后组装好key之后看该key是否存在，存在则进行累计，否则往redis中添加该key。

最近10分钟，同一个账号的下单金额，采样周期设置为30次。
指标对象创建以及更新时间：1597373586422[2020-08-13 10:00:00] 

事件1：在1597373586422[2020-08-13 10:00:00]这个时间点用户pez1420的下单金额为100
key: 0d666c909266_1_pez1420_0 value=100  [1597373586422]
其中0d666c909266是指指标ID,版本号为1,主维度的值为pez1420,时间间隔序号为0(0=0/30),订单金额=100

事件2：在1597373587568[2020-08-13 10:05:00]这个时间点用户pez1420的下单金额为50
key: 0d666c909266_1_pez1420_0 150  [1597373587568]
其中0d666c909266是指指标ID,版本号为1,主维度的值为pez1420,时间间隔序号为0(0=5/30),订单金额=50 + 100 = 150

事件3：在1597373597567[2020-08-13 10:31:00]这个时间点用户pez1420的下单金额为20
key: 0d666c909266_1_pez1420_1 20  [在1597373597567]
其中0d666c909266是指指标ID,版本号为1,主维度的值为pez1420,时间间隔序号为1(1=31/30),订单金额=20

事件4：在1597373597564[2020-08-13 10:50:00]这个时间点用户pez1420的下单金额为60
key: 0d666c909266_1_pez1420_1 80  [1597373597564]
其中0d666c909266是指指标ID,版本号为1,主维度的值为pez1420,时间间隔序号为1(1=50/30),订单金额=20 + 60=80


#### 如何批量获取key？
每次获取指标值时，我们都是先计算出需要的key集合（比如我要获取“单个账号最近10分钟的下单量”，我可能需要获取30个key，因为每个key的跨度是20s），然后获取到对应的value集合，再进行累加。
而实际上我们只是需要累加后的值，这里可以通过redis+lua脚本进行优化后，脚本里面直接根据key集合获取value进行累加然后返回给客户端，这样就较少了每次响应的数据量。

+ 如何保证指标的计算结果不丢失？
目前的指标是存储在redis里面的，后来会切到solo-ldb，ldb提供了持久化的存储引擎，可以保证数据不丢失。


### 2、饿了吗计数器key以及时间窗口设计

#### 时间窗口设计

计数器设计中有一大难点是时间窗口的设计。当初想到的方案有2种：
第一种是每隔xx时间，例如：每隔1天，每隔3小时，每隔5分钟。如果计数器选择的类型是每隔1小时，就将一天划分成24个1小时；
如果是每隔2小时，就将一天划分成12个2小时；这种时间划分有一个缺点，如果是每隔5小时这种的，是没有办法整除的。所以这种时间窗口方案被我们抛弃了。
第二种是最近xx时间，例如：最近1天，最近3小时，最近5分钟。我们还是以最近xx小时举例，不管我们设置的是最近3小时，
还是最近5小时，我们在redis中都是以小时账的形式进行存储，获取的时候，只要将前几小时的小时账进行合并就可以了，那么同理如果是天，就是日账，月就是月账。如图所示：

对于这种时间窗口有一个弊端，如果滑动时间窗口粒度很长，计算的复杂度就会越高，例如 统计最近10小时的计数器，就需要累加10个小时账；
为了应对这种粒度很长的时间窗口，我们提出了中间值的概念，将历史的时间窗口计数器计算成中间值，那么无论滑动窗口多长，只需要计算一次，即： 计数器 = 当前时间窗口值 + 中间值

最终风控采用的时间窗口是第二种方案。

#### 计数器key的设计

faraday 中key主要由 编号+主体+客体+统计方式+时间戳 组成，由于Redis是纯内存的，所以成本也不算低。
为了降低成本，我们需要缩减key的长度，首先去掉了一些不必要的前缀，这些前缀加起来是33个byte，如果以10亿个计数器计算，去掉这些前缀，可以节省近31G的内存空间。
另外对于时间戳，我们是采用yyyyMMdd 这种字符串形式存储，第一比较容易阅读，第二相比timestamp存储的字节更少。

计数器的配置主要是由计数器的使用者自助完成。计数器在后台配置如图所示：
主要有三大模块组成，分别是：

+ 1、计数器模型配置器
主要解析调用方的模型参数，并从配置视图中心获取计数器模型配置信息。

+ 2、计数器逻辑执行器
负责各种计数器的逻辑操作，例如：count、sum、max、min等。

+ 3、异步引擎
作用有2个方面，第一是异步化入库，防止操作数据库，导致接口性能降低，第二是化并行为串行，降低高并发带来的数据不一致问题。
